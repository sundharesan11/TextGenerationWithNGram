{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fake_useragent import UserAgent\n",
    "user_agent = UserAgent().random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikipediaapi\n",
    "\n",
    "wiki = wikipediaapi.Wikipedia(\n",
    "    language='en',\n",
    "    user_agent='user_agent'\n",
    ")\n",
    "\n",
    "page_title = 'M S Dhoni'\n",
    "\n",
    "page = wiki.page(page_title)\n",
    "\n",
    "text_content = page.text\n",
    "\n",
    "f = \"msd.txt\"\n",
    "with open(f, 'w', encoding='utf-8') as file:\n",
    "    file.write(text_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    for punct in string.punctuation:\n",
    "        text = text.replace(punct, ' '+punct+' ')\n",
    "    t = text.split()\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ngrams(n, tokens):\n",
    "    ngrams = []\n",
    "    tokens = (n-1)*['<START>']+tokens\n",
    "    for i in range(n - 1, len(tokens)):\n",
    "        context = tuple(tokens[i - p - 1] for p in reversed(range(n - 1)))\n",
    "        target_word = tokens[i]\n",
    "        ngrams.append((context, target_word))\n",
    "    return ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(ngram_counter, context, sentence, n):\n",
    "    ngrams = get_ngrams(n, tokenize(sentence))\n",
    "    for ngram in ngrams:\n",
    "        if ngram in ngram_counter:\n",
    "            ngram_counter[ngram] += 1.0\n",
    "        else:\n",
    "            ngram_counter[ngram] = 1.0\n",
    "\n",
    "        prev_words, target_word = ngram\n",
    "        if prev_words in context:\n",
    "            context[prev_words].append(target_word)\n",
    "        else:\n",
    "            context[prev_words] = [target_word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob(ngram_counter, context, context_token, token):\n",
    "    count_of_token = ngram_counter[(context_token, token)]\n",
    "    count_of_context = float(len(context[context_token]))\n",
    "    result = count_of_token / count_of_context\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_token(context, context_token, ngram_counter):\n",
    "    r = random.random()\n",
    "    map_to_probs = {}\n",
    "    token_of_interest = context[context_token]\n",
    "    for token in token_of_interest:\n",
    "        map_to_probs[token] = prob(ngram_counter, context, context_token, token)\n",
    "\n",
    "    sum = 0\n",
    "    for token in sorted(map_to_probs):\n",
    "        sum += map_to_probs[token]\n",
    "        if sum > r:\n",
    "            return token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(n, context, token_count, ngram_counter):\n",
    "    context_queue = (n - 1) * ['<START>']\n",
    "    result = []\n",
    "    for _ in range(token_count):\n",
    "        obj = random_token(context, tuple(context_queue), ngram_counter)\n",
    "        result.append(obj)\n",
    "        if n > 1:\n",
    "            context_queue.pop(0)\n",
    "            if obj == '.':\n",
    "                context_queue = (n - 1) * ['<START>']\n",
    "            else:\n",
    "                context_queue.append(obj)\n",
    "    return ' '.join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ngram_model(n, path):\n",
    "    ngram_counter = {}\n",
    "    context = {}\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "        sentences = text.split('.')\n",
    "        for sentence in sentences:\n",
    "            sentence += '.'\n",
    "            update(ngram_counter, context, sentence, n)\n",
    "    return ngram_counter, context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text:\n",
      "deviates scored was Indian popularity month international 09 , a one He class ODI talent tour against years - season the 2019 more for until\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "n_gram= 3\n",
    "ngram_counter, context = create_ngram_model(n_gram, 'msd.txt')\n",
    "random.seed(7)\n",
    "print('Generated text:')\n",
    "print(generate_text(n_gram, context, 25, ngram_counter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
